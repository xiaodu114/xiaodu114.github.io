<!DOCTYPE html>
<html lang="zh-cmn-Hans">
    <head>
        <meta charset="UTF-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1.0" />
        <meta http-equiv="X-UA-Compatible" content="ie=edge" />
        <title>ChatTTS - xiaodu114.github.io</title>
        <meta name="keywords" content="xiaodu114,ChatTTS,Text-to-Speech,æ–‡æœ¬è½¬è¯­éŸ³,è¯­éŸ³åˆæˆ" />
        <meta name="description" content="æˆ‘å’Œ ChatTTS çš„æ•…äº‹ã€‚ChatTTS æ˜¯ä¸€æ¬¾é€‚ç”¨äºæ—¥å¸¸å¯¹è¯çš„ç”Ÿæˆå¼è¯­éŸ³æ¨¡å‹ã€‚" />

        <script src="/p/_/js/main.js"></script>
    </head>

    <body>
        <!-- githubè®¿é—®åœ°å€ï¼š/p/mllm/chatTTS/index.html -->
        <div class="blog-page">
            <h1>ChatTTS</h1>
            <p>GitHubï¼š<a href="https://github.com/2noise/ChatTTS" target="_blank" rel="noopener noreferrer">2noise/ChatTTS: A generative speech model for daily dialogue.</a>ã€‚ä»–æ˜¯è¿™æ ·ä»‹ç»çš„ï¼šä¸€æ¬¾é€‚ç”¨äºæ—¥å¸¸å¯¹è¯çš„ç”Ÿæˆå¼è¯­éŸ³æ¨¡å‹ã€‚</p>
            <ul>
                <li>
                    <a href="https://chattts.com/zh" target="_blank" rel="noopener noreferrer">ChatTTS: Text-to-Speech For Chat</a>
                </li>
                <li>
                    <a href="https://chattts.in/zh" target="_blank" rel="noopener noreferrer">ChatTTS - è‡ªç„¶ã€è¡¨è¾¾ä¸°å¯Œçš„æ–‡æœ¬è½¬è¯­éŸ³</a>
                </li>
                <li></li>
                <li>
                    <a href="https://github.com/CCmahua/ChatTTS-Enhanced" target="_blank" rel="noopener noreferrer">CCmahua/ChatTTS-Enhanced: ChatTTS è¯­éŸ³å¢å¼ºç‰ˆ</a>
                </li>
                <li></li>
                <li>
                    <a href="https://github.com/6drf21e/ChatTTS_Speaker" target="_blank" rel="noopener noreferrer">6drf21e/ChatTTS_Speaker: ChatTTS 2000æ¡éŸ³è‰²ç¨³å®šæ€§æ‰“åˆ†ğŸ¥‡+åŒºåˆ†ç”·å¥³å¹´é¾„ğŸ‘§+åœ¨çº¿è¯•å¬ğŸ”ˆ ChatTTS 2K Speaker Stability Score & Categorized by Gender and Age & Audio Preview</a>
                </li>
                <li>
                    <a href="https://www.modelscope.cn/studios/ttwwwaa/ChatTTS_Speaker" target="_blank" rel="noopener noreferrer">ChatTTS ç¨³å®šéŸ³è‰²/åŒºåˆ†ç”·å¥³ Â· åˆ›ç©ºé—´</a>
                </li>
            </ul>
            <h2>Windows</h2>
            <h3>ä¸‹è½½é¡¹ç›®</h3>
            <p><line-code>2024-12-26</line-code>è¿™é‡Œä¸‹è½½çš„æ˜¯<line-code>v0.2.1</line-code>ï¼Œå¦‚ä¸‹å›¾ï¼š</p>
            <p>
                <img src="./image/1.png" alt="ChatTTS é¡¹ç›®ï¼Œä¸‹è½½ç‰ˆæœ¬æ˜¯ v0.2.1ï¼Œè§£å‹ä½ç½®" />
            </p>
            <h3>è™šæ‹Ÿç¯å¢ƒ/å®‰è£…ä¾èµ–</h3>
            <pre ddz-class="here-need-to-handle-by-highlight" ddz-lang="bash">
conda create -n chattts python=3.11
conda activate chattts
pip install -r requirements.txt
            </pre>
            <details>
                <summary>ç‚¹å‡»æŸ¥çœ‹è¯¦æƒ…</summary>
                <p>
                    <img src="./image/2.png" alt="ChatTTS é¡¹ç›®ï¼Œconda åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ" />
                </p>
                <p>
                    <img src="./image/3.png" alt="ChatTTS é¡¹ç›®ï¼Œæ¿€æ´»è™šæ‹Ÿç¯å¢ƒã€å®‰è£…ä¾èµ–" />
                </p>
                <p>
                    <img src="./image/4.png" alt="ChatTTS é¡¹ç›®ï¼Œå®‰è£…ä¾èµ–æˆåŠŸ" />
                </p>
            </details>
            <h3>å¯åŠ¨é¡¹ç›® - WebUI</h3>
            <p>æˆ‘å»ï¼Œå¥½é¡ºåˆ©å•Šï¼è¿™é‡Œç›´æ¥å¯åŠ¨å¸¦ Web é¡µé¢ï¼Œå¯¹ Web æœ‰å¤©ç”Ÿçš„å¥½æ„Ÿâ€¦â€¦</p>
            <pre ddz-class="here-need-to-handle-by-highlight" ddz-lang="bash">
python examples/web/webui.py
            </pre>
            <p>è¿™ä¸€å¯åŠ¨å¯ä¸å¾—äº†å•Šï¼Œè¿™ä¸€æ‹‰æµæ—¥å¿—éƒ½çœ‹ä¸è¿‡æ¥å•Šï¼è‡ªå·±å·å·ä¸‹è½½äº†ä¸å°‘ä¸œè¥¿ï¼Œè¯·çœ‹ï¼š</p>
            <p>
                <img src="./image/5.png" alt="ChatTTS é¡¹ç›®ï¼Œå¯åŠ¨é¡¹ç›®ï¼špython examples/web/webui.py ã€‚ç¬¬ä¸€æ¬¡å¯åŠ¨ï¼Œä¸‹è½½ä¾èµ–æ¨¡å‹" />
            </p>
            <p>
                <img src="./image/6.png" alt="ChatTTS é¡¹ç›®ï¼Œç¬¬ä¸€æ¬¡å¯åŠ¨ WebUI é¡¹ç›®æ—¶ï¼Œä¸‹è½½çš„ä¾èµ–æ¨¡å‹" />
            </p>
            <ul>
                <li>
                    <a href="https://github.com/fumiama/RVC-Models-Downloader" target="_blank" rel="noopener noreferrer">https://github.com/fumiama/RVC-Models-Downloader</a>
                </li>
                <li>
                    <a href="https://hf-mirror.com/2Noise/ChatTTS" target="_blank" rel="noopener noreferrer">https://hf-mirror.com/2Noise/ChatTTS ï¼ˆè¿™é‡Œå°†é“¾æ¥æ›¿æ¢æˆå›½å†…çš„äº†ï¼‰</a>
                </li>
            </ul>
            <p>äººå®¶ä¸‹è½½å°±ä¸‹è½½å‘—ï¼Œäººå®¶æœ€åè¿˜ä¸æ˜¯è·‘èµ·æ¥äº†ï¼Œä½ çœ‹ï¼š</p>
            <p>
                <img src="./image/7.png" alt="ChatTTS é¡¹ç›®ï¼Œå¯åŠ¨ WebUI é¡¹ç›®æˆåŠŸï¼Œæµè§ˆå™¨é¡µé¢æˆªå›¾" />
            </p>
            <p>éšåæµ‹è¯•äº†ä¸€ä¸‹ï¼Œå¾ˆé¡ºåˆ©ï¼Œçœ‹ä¸€ä¸‹æ•ˆæœæˆªå›¾å§ï¼š</p>
            <p>
                <img src="./image/8.png" alt="ChatTTS é¡¹ç›®ï¼Œå¯åŠ¨ WebUI é¡¹ç›®ä¹‹åï¼Œç”Ÿæˆè¯­éŸ³æˆåŠŸ" />
            </p>
            <h3>å¯åŠ¨é¡¹ç›® - API</h3>
            <p>è¿™æ‰æ˜¯å’±æœ€æƒ³è¦çš„ï¼Œæœ‰äº†å¥¹ï¼Œæ‰èƒ½å’Œå…¶ä»–çš„åº”ç”¨ç»“åˆåœ¨ä¸€èµ·ã€‚å½“ç„¶ï¼Œé¡¹ç›®è¿˜æ˜¯å¾ˆè´´å¿ƒçš„ï¼Œæä¾›äº† API å¯åŠ¨æ–¹å¼ï¼š<line-code>examples/api</line-code>ã€‚è¯¥ç›®å½•ä¸‹æœ‰ä¸€ä¸ª<line-code>requirements.txt</line-code>æ–‡ä»¶ï¼Œä»…åŒ…å«äº†ä¸¤ä¸ªä¾èµ–ï¼šfastapiã€requestsï¼Œå’±åˆç»™ä»–æ·»åŠ äº†ä¸€ä¸ª uvicorn ã€‚ä¹‹ååœ¨å®‰è£…ä¸€ä¸‹<line-code>pip install -r examples/api/requirements.txt</line-code>ï¼Œå¦‚ä¸‹å›¾ï¼š</p>
            <p>
                <img src="./image/9.png" alt="ChatTTS é¡¹ç›®ï¼Œå¯åŠ¨ API é¡¹ç›®ï¼Œå®‰è£…ä¾èµ–" />
            </p>
            <p>å®‰è£…æˆåŠŸä¹‹åå°±å¯ä»¥å¯åŠ¨äº†<line-code>python examples/api/main.py</line-code>ï¼Œæ¥äº†ï¼Œæ¥äº†ï¼Œæ€ä¹ˆå°±ä¸èƒ½äº†è®©äººçœå¿ƒå‘¢ï¼Ÿ</p>
            <p>
                <img src="./image/10.png" alt="ChatTTS é¡¹ç›®ï¼Œå¯åŠ¨ API é¡¹ç›®ï¼Œé¦–æ¬¡å¯åŠ¨æŠ¥é”™" />
            </p>
            <p>æ”¹åŠ¨äº†å¥½å‡ å¤„åœ°æ–¹ï¼Œè¿™é‡Œå°±ç›´æ¥å…¨éƒ¨å¼„è¿‡æ¥äº†ï¼Œå¦‚ä¸‹ï¼š</p>
            <details>
                <summary>ç‚¹å‡»æŸ¥çœ‹è¯¦æƒ…</summary>
                <pre ddz-class="here-need-to-handle-by-highlight" ddz-lang="python">
import os
import sys
now_dir = os.getcwd()
sys.path.append(now_dir)

from pydantic import BaseModel
import torch
from tools.logger import get_logger
from tools.audio import pcm_arr_to_mp3_view
import ChatTTS
from typing import Optional
import io
import zipfile

import uvicorn
from fastapi import FastAPI
from fastapi.responses import StreamingResponse
from contextlib import asynccontextmanager


if sys.platform == "darwin":
    os.environ["PYTORCH_ENABLE_MPS_FALLBACK"] = "1"

logger = get_logger("Command")


@asynccontextmanager
async def lifespan(app: FastAPI):
    global chat

    chat = ChatTTS.Chat(get_logger("ChatTTS"))
    logger.info("Initializing ChatTTS...")
    if chat.load():
        logger.info("Models loaded successfully.")
    else:
        logger.error("Models load failed.")
        sys.exit(1)
    yield

app = FastAPI(lifespan=lifespan)

class ChatTTSParams(BaseModel):
    text: list[str]
    stream: bool = False
    lang: Optional[str] = None
    skip_refine_text: bool = False
    refine_text_only: bool = False
    use_decoder: bool = True
    do_text_normalization: bool = True
    do_homophone_replacement: bool = False
    params_refine_text: ChatTTS.Chat.RefineTextParams
    params_infer_code: ChatTTS.Chat.InferCodeParams

@app.post("/generate_voice")
async def generate_voice(params: ChatTTSParams):
    logger.info("Text input: %s", str(params.text))

    # audio seed
    if params.params_infer_code.manual_seed is not None:
        torch.manual_seed(params.params_infer_code.manual_seed)
        params.params_infer_code.spk_emb = chat.sample_random_speaker()

    # text seed for text refining
    if params.params_refine_text:
        text = chat.infer(
            text=params.text, skip_refine_text=False, refine_text_only=True
        )
        logger.info(f"Refined text: {text}")
    else:
        # no text refining
        text = params.text

    logger.info("Use speaker:")
    logger.info(params.params_infer_code.spk_emb)

    logger.info("Start voice inference.")
    wavs = chat.infer(
        text=text,
        stream=params.stream,
        lang=params.lang,
        skip_refine_text=params.skip_refine_text,
        use_decoder=params.use_decoder,
        do_text_normalization=params.do_text_normalization,
        do_homophone_replacement=params.do_homophone_replacement,
        params_infer_code=params.params_infer_code,
        params_refine_text=params.params_refine_text,
    )
    logger.info("Inference completed.")

    # zip all of the audio files together
    buf = io.BytesIO()
    with zipfile.ZipFile(
        buf, "a", compression=zipfile.ZIP_DEFLATED, allowZip64=False
    ) as f:
        for idx, wav in enumerate(wavs):
            f.writestr(f"{idx}.mp3", pcm_arr_to_mp3_view(wav))
    logger.info("Audio generation successful.")
    buf.seek(0)

    response = StreamingResponse(buf, media_type="application/zip")
    response.headers["Content-Disposition"] = "attachment; filename=audio_files.zip"
    return response

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=13140)
                </pre>
            </details>
            <p>ä¹‹åå°±å¯ä»¥æˆåŠŸå¯åŠ¨äº†ï¼Œå¦‚ä¸‹å›¾ï¼š</p>
            <p>
                <img src="./image/11.png" alt="ChatTTS é¡¹ç›®ï¼Œå¯åŠ¨ API é¡¹ç›®æˆåŠŸï¼Œæµè§ˆå™¨ API æ¥å£æ–‡æ¡£" />
            </p>
            <details>
                <summary>ç‚¹å‡»æŸ¥çœ‹å…·ä½“çš„ä¾èµ–ç‰ˆæœ¬</summary>
                <pre>
#	requirements.txt
numpy==1.26.4
numba==0.60.0
torch==2.5.1
torchaudio==2.5.1
tqdm==4.67.1
vector_quantize_pytorch
transformers==4.47.1
vocos==0.1.0
IPython==8.31.0
gradio==5.9.1
pybase16384==0.3.7
pynini==2.1.5; sys_platform == 'linux'
WeTextProcessing; sys_platform == 'linux'
nemo_text_processing; sys_platform == 'linux'
av==14.0.1
pydub==0.25.1

#	examples/api/requirements.txt
fastapi==0.115.6
requests==2.32.3
uvicorn==0.34.0
                </pre>
            </details>
            <p>å¿ƒæƒ³ï¼šç°åœ¨æ€»è¡Œäº†å§ï¼ä½ æƒ³å¤šäº†ï¼Œè¿˜æ˜¯æœ‰é—®é¢˜å•Šï¼Œå¦‚ä¸‹ï¼š</p>
            <details>
                <summary>ç‚¹å‡»æŸ¥çœ‹é”™è¯¯å †æ ˆ</summary>
                <pre style="overflow-x: auto">
INFO:     127.0.0.1:55969 - "POST /generate_voice HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "C:\Users\xiaodu\.conda\envs\chattts\Lib\site-packages\uvicorn\protocols\http\h11_impl.py", line 403, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\xiaodu\.conda\envs\chattts\Lib\site-packages\uvicorn\middleware\proxy_headers.py", line 60, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\xiaodu\.conda\envs\chattts\Lib\site-packages\fastapi\applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "C:\Users\xiaodu\.conda\envs\chattts\Lib\site-packages\starlette\applications.py", line 113, in __call__
    await self.middleware_stack(scope, receive, send)
  File "C:\Users\xiaodu\.conda\envs\chattts\Lib\site-packages\starlette\middleware\errors.py", line 187, in __call__
    raise exc
  File "C:\Users\xiaodu\.conda\envs\chattts\Lib\site-packages\starlette\middleware\errors.py", line 165, in __call__
    await self.app(scope, receive, _send)
  File "C:\Users\xiaodu\.conda\envs\chattts\Lib\site-packages\starlette\middleware\exceptions.py", line 62, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "C:\Users\xiaodu\.conda\envs\chattts\Lib\site-packages\starlette\_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "C:\Users\xiaodu\.conda\envs\chattts\Lib\site-packages\starlette\_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "C:\Users\xiaodu\.conda\envs\chattts\Lib\site-packages\starlette\routing.py", line 715, in __call__
    await self.middleware_stack(scope, receive, send)
  File "C:\Users\xiaodu\.conda\envs\chattts\Lib\site-packages\starlette\routing.py", line 735, in app
    await route.handle(scope, receive, send)
  File "C:\Users\xiaodu\.conda\envs\chattts\Lib\site-packages\starlette\routing.py", line 288, in handle
    await self.app(scope, receive, send)
  File "C:\Users\xiaodu\.conda\envs\chattts\Lib\site-packages\starlette\routing.py", line 76, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "C:\Users\xiaodu\.conda\envs\chattts\Lib\site-packages\starlette\_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "C:\Users\xiaodu\.conda\envs\chattts\Lib\site-packages\starlette\_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "C:\Users\xiaodu\.conda\envs\chattts\Lib\site-packages\starlette\routing.py", line 73, in app
    response = await f(request)
               ^^^^^^^^^^^^^^^^
  File "C:\Users\xiaodu\.conda\envs\chattts\Lib\site-packages\fastapi\routing.py", line 301, in app
    raw_response = await run_endpoint_function(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\xiaodu\.conda\envs\chattts\Lib\site-packages\fastapi\routing.py", line 212, in run_endpoint_function
    return await dependant.call(**values)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\mllm\ChatTTS-0.2.1\examples\api\main.py", line 92, in generate_voice
    wavs = chat.infer(
           ^^^^^^^^^^^
  File "F:\mllm\ChatTTS-0.2.1\ChatTTS\core.py", line 221, in infer
    return next(res_gen)
           ^^^^^^^^^^^^^
  File "F:\mllm\ChatTTS-0.2.1\ChatTTS\core.py", line 385, in _infer
    for result in self._infer_code(
                  ^^^^^^^^^^^^^^^^^
  File "C:\Users\xiaodu\.conda\envs\chattts\Lib\site-packages\torch\utils\_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "F:\mllm\ChatTTS-0.2.1\ChatTTS\core.py", line 485, in _infer_code
    self.speaker.decode_prompt(params.spk_smp)
  File "C:\Users\xiaodu\.conda\envs\chattts\Lib\site-packages\torch\utils\_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "F:\mllm\ChatTTS-0.2.1\ChatTTS\model\speaker.py", line 112, in decode_prompt
    lzma.decompress(
  File "C:\Users\xiaodu\.conda\envs\chattts\Lib\lzma.py", line 343, in decompress
    res = decomp.decompress(data)
          ^^^^^^^^^^^^^^^^^^^^^^^
_lzma.LZMAError: Corrupt input data
                </pre>
            </details>
            <p>è¿™ä¸ªé”™è¯¯å‘ç°æ˜¯<line-code>chat.infer(...)</line-code>æ–¹æ³•å†…éƒ¨å‡ºäº†é—®é¢˜ï¼Œæ„Ÿè§‰åº”è¯¥æ˜¯å‚æ•°çš„é—®é¢˜ï¼Œå› ä¸º WebUI é¡¹ç›®ä¹Ÿä¼šè°ƒç”¨è¿™ä¸ªæ–¹æ³•ï¼Œæœ‰æ—¶é—´å¯¹æ¯”ä¸€ä¸‹è¿™ä¸¤å¤„è°ƒç”¨ä¼ å…¥çš„å‚æ•°æœ‰ä½•ä¸åŒ</p>
            <h3>Python åŒ…</h3>
            <p>æˆ‘å»ï¼Œå…¶ä»–çš„éƒ½æ˜¯æµ®äº‘ï¼Œè¿™é‡Œæ‰æ˜¯é‡ç‚¹ï¼Œéƒ½æœ‰ Python åŒ…äº†ï¼Œè¿˜è¦å•¥ API å•Šï¼Œé›†æˆæ›´æ–¹ä¾¿äº†ğŸ‘ğŸ‘ğŸ‘ã€‚å®˜ç½‘çš„â€œå¼€å‘æ•™ç¨‹â€ç« èŠ‚ç»™å‡ºäº†ä½¿ç”¨æ–¹æ³•ï¼š</p>
            <p>
                <img src="./image/12.png" alt="ChatTTS é¡¹ç›®ï¼Œå¼€å‘æ•™ç¨‹ï¼ŒPython åŒ…ä½¿ç”¨æ–¹æ³•" />
            </p>
        </div>
    </body>
</html>
