<!DOCTYPE html>
<html lang="zh-cmn-Hans">
    <head>
        <meta charset="UTF-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1.0" />
        <meta http-equiv="X-UA-Compatible" content="ie=edge" />
        <title>CosyVoice - xiaodu114.github.io</title>
        <meta name="keywords" content="xiaodu114,CosyVoice,tts,文本转语音,声音克隆" />
        <meta name="description" content="我和 SenseVoice 的故事。Multi-lingual large voice generation model, providing inference, training and deployment full-stack ability." />

        <script src="/p/_/js/main.js"></script>
    </head>

    <body>
        <!-- github访问地址：/p/mllm/cosyVoice/index.html -->
        <div class="blog-page">
            <h1>CosyVoice</h1>
            <p>GitHub：<a href="https://github.com/FunAudioLLM/CosyVoice" target="_blank" rel="noopener noreferrer">FunAudioLLM/CosyVoice: Multi-lingual large voice generation model, providing inference, training and deployment full-stack ability.</a></p>
            <h2>下载模型</h2>
            <p>提前下载好需要的模型，这里的下载路径是<line-code>E:\llm\pretrained_models</line-code></p>
            <pre ddz-class="here-need-to-handle-by-highlight" ddz-lang="bash">
# git模型下载，请确保已安装git lfs
mkdir -p pretrained_models
git clone https://www.modelscope.cn/iic/CosyVoice2-0.5B.git pretrained_models/CosyVoice2-0.5B
git clone https://www.modelscope.cn/iic/CosyVoice-300M.git pretrained_models/CosyVoice-300M
git clone https://www.modelscope.cn/iic/CosyVoice-300M-25Hz.git pretrained_models/CosyVoice-300M-25Hz
git clone https://www.modelscope.cn/iic/CosyVoice-300M-SFT.git pretrained_models/CosyVoice-300M-SFT
git clone https://www.modelscope.cn/iic/CosyVoice-300M-Instruct.git pretrained_models/CosyVoice-300M-Instruct
git clone https://www.modelscope.cn/iic/CosyVoice-ttsfrd.git pretrained_models/CosyVoice-ttsfrd
            </pre>
            <h2>windows</h2>
            <p>这是和<line-code>CosyVoice</line-code>约会的第一个地方</p>
            <h3>踩坑</h3>
            <p>看了官方的部署说明之后，觉得小意思，没有<line-code>conda</line-code>也没问题，咱有<line-code>pip</line-code>啊！哎，不听劝啊，费用自己折腾……你说你跑起来了也行啊，结果出现了一堆错误，还解决不了。撞了南墙就知道回头了</p>
            <p>
                <img src="./image/1.png" alt="CosyVoice 项目，pip 创建虚拟环境并安装依赖" />
            </p>
            <p>
                <img src="./image/2.png" alt="CosyVoice 项目，pip 安装依赖报错：ModuleNotFoundError:No module named Cython" />
            </p>
            <p><line-code>ModuleNotFoundError:No module named Cython</line-code>这个错误太牛逼了，尝试了各种办法没有解决，甚至还尝试了<a href="https://github.com/astral-sh/uv/" target="_blank" rel="noopener noreferrer">astral-sh/uv: An extremely fast Python package and project manager, written in Rust.</a>最后不得不向<line-code>conda</line-code>低头啊。如何安装<line-code>conda</line-code>你可以参考这个：<a href="/p/python/index.html" target="_blank" rel="noopener noreferrer">Python - xiaodu114.github.io</a></p>
            <h3>克隆项目</h3>
            <p><line-code>2024-12-18</line-code>克隆的项目，此时已是 2.0 版本了。这里将项目放到了<line-code>F:\mllm</line-code>目录下，如下图：</p>
            <p>
                <img src="./image/3.png" alt="CosyVoice 项目，git 克隆项目" />
            </p>
            <pre ddz-class="here-need-to-handle-by-highlight" ddz-lang="bash">
git clone --recursive https://github.com/FunAudioLLM/CosyVoice.git

#   该项目依赖子模块 Matcha-TTS，保证已经克隆下来，如果上面没有克隆下来，可以执行下面的命令
cd CosyVoice
git submodule update --init --recursive 
            </pre>
            <h3>虚拟环境/安装依赖</h3>
            <p>注意啊！注意啊！注意啊！这里用的<line-code>conda</line-code>创建的虚拟环境。还是得听话，老老实实按照官网上弄，就是爽啊，一路顺风，创建虚拟环境并激活、安装依赖都是一步到位，没有出现任务和问题。</p>
            <pre ddz-class="here-need-to-handle-by-highlight" ddz-lang="bash">
conda create -n cosyvoice python=3.10
conda activate cosyvoice
# pynini is required by WeTextProcessing, use conda to install it as it can be executed on all platform.
conda install -y -c conda-forge pynini==2.1.5
pip install -r requirements.txt 
            </pre>
            <details>
                <summary>点击查看</summary>
                <p>
                    <img src="./image/4.png" alt="CosyVoice 项目，conda 创建虚拟环境" />
                </p>
                <p>
                    <img src="./image/5.png" alt="CosyVoice 项目，激活虚拟环境并安装 pynini" />
                </p>
                <p>
                    <img src="./image/6.png" alt="CosyVoice 项目，安装依赖" />
                </p>
                <p>
                    <img src="./image/7.png" alt="CosyVoice 项目，安装依赖成功" />
                </p>
            </details>
            <h3>运行项目-WebUI</h3>
            <p>环境和模型都弄好了，下面就是启动项目了，这里用的是<line-code>CosyVoice2-0.5B</line-code>的模型。通往成功的道路上，永远少不了磕磕绊绊，这不问题又来了：</p>
            <pre ddz-class="here-need-to-handle-by-highlight" ddz-lang="bash">
python webui.py --model_dir "E:/llm/pretrained_models/CosyVoice2-0.5B"
            </pre>
            <p>
                <img src="./image/8.png" alt="CosyVoice 项目，启动失败，缺少依赖：onnxruntime" />
            </p>
            <p>这个问题还好处理，直接安装一下就行了。不过疑问的是<line-code>requirements.txt</line-code>文件中有这个依赖项，之不错他是这样写的<line-code>onnxruntime==1.18.0; sys_platform == 'darwin' or sys_platform == 'windows'</line-code>。网上有的说只保留<line-code>onnxruntime==1.18.0;</line-code>即可。这里是后面补充安装的，发现也没有问题</p>
            <p>
                <img src="./image/9.png" alt="CosyVoice 项目，后补安装 onnxruntime" />
            </p>
            <p>搞定后，再次启动项目，看看这次的效果：</p>
            <p>
                <img src="./image/10.png" alt="CosyVoice 项目，启动成功" />
            </p>
            <p>
                <img src="./image/11.png" alt="CosyVoice 项目，启动成功，浏览器截图" />
            </p>
            <h4>测试项目</h4>
            <h5>3s极速复刻</h5>
            <p>对这个比较感兴趣，先尝试这个。需要复刻（或者说合成）的文本时<line-code>目光所至皆为华夏，五星闪耀皆为信仰。</line-code>源音频是我在页面中直接录制的</p>
            <p>
                <img src="./image/12.png" alt="CosyVoice 项目，启动成功，测试3s极速复刻" />
            </p>
            <p>
                <img src="./image/13.png" alt="CosyVoice 项目，启动成功，测试3s极速复刻，复刻成功" />
            </p>
            <p>虽然咱的老电脑有点慢，但还是成功了，并且感觉还挺像，非常满意……真是不禁夸啊！想着把录制的源音频和复刻之后的音频下载下来，结果下载的一个 txt 文件，一个是 wav 文件，但是文件大小为 0 。😵😵😵</p>
            <p>
                <img src="./image/14.png" alt="CosyVoice 项目，启动成功，测试3s极速复刻，复刻成功，下载文件" />
            </p>
            <p>于是就自己看了一下源码，心想：既然下载不下来，我就自己保存下来，临时救救场。如下：</p>
            <pre ddz-class="here-need-to-handle-by-highlight" ddz-lang="bash">
#   这里是自己添加的代码
from datetime import datetime
source_audio_filename = 'source_' + datetime.now().strftime('%Y-%m-%d %H-%M-%S-%f')[:-3] + '.wav'
clone_audio_filename = 'clone_' + datetime.now().strftime('%Y-%m-%d %H-%M-%S-%f')[:-3] + '.wav'
prompt_wav_loaded = load_wav(prompt_wav, prompt_sr)
torchaudio.save(source_audio_filename, prompt_wav_loaded, prompt_sr) 

#   注意代码的位置
torchaudio.save(clone_audio_filename, i['tts_speech'], cosyvoice.sample_rate)
            </pre>
            <p>
                <img src="./image/15.png" alt="CosyVoice 项目，修改代码，为保存源音频和复刻音频" />
            </p>
            <p>进行的还挺顺利的，如下图：</p>
            <p>
                <img src="./image/16.png" alt="CosyVoice 项目，修改代码，重新启动之后，成功保存源音频和复刻音频" />
            </p>
            <div style="display: flex; justify-content: space-between">
                <div>
                    <div>录制的源音频：</div>
                    <audio src="./audio/source_2024-12-17 18-04-16-192.wav" controls="controls"></audio>
                </div>
                <div>
                    <div>克隆的音频：</div>
                    <audio src="./audio/clone_2024-12-17 18-04-16-192.wav" controls="controls"></audio>
                </div>
            </div>
            <h3>运行项目-API</h3>
            <p>WebUI 不是我们的终点，我们需要的是 API，但是<line-code>runtime\python\fastapi\server.py</line-code>仅支持 1.0。我们自己弄一个吧，不是很麻烦：</p>
            <p>先看一下类库方式使用的简单示例：</p>
            <pre ddz-class="here-need-to-handle-by-highlight" ddz-lang="bash">
import os
import sys
from cosyvoice.cli.cosyvoice import CosyVoice2
from cosyvoice.utils.file_utils import load_wav
import torchaudio

ROOT_DIR = os.path.dirname(os.path.abspath(__file__))
sys.path.append('{}/third_party/Matcha-TTS'.format(ROOT_DIR))

if __name__ == "__main__":
    tts_text = "我们生在红旗下，长在春风里，人民有信仰，国家有力量，民族有希望，目光所至皆为华夏，五星闪耀，皆为信仰，愿以吾辈之青春，护我盛世之中华 ，此生无悔入华夏，来生还做中国人！"
    prompt_text = "你今天晚上吃的什么饭呀"

    cosyvoice = CosyVoice2('E:/llm/pretrained_models/CosyVoice2-0.5B',load_jit=True, load_onnx=False, load_trt=False)
    prompt_speech_16k = load_wav('source_001.wav', 16000)

    for i, j in enumerate(cosyvoice.inference_zero_shot(tts_text, prompt_text, prompt_speech_16k, stream=False)):
        torchaudio.save('zero_shot_ddz_{}.wav'.format(i), j['tts_speech'], cosyvoice.sample_rate)
            </pre>
            <p>上面的代码跑通之后，开始弄API，入口文件为<line-code>api.py</line-code>，代码如下：</p>
            <details>
                <summary>点击查看代码详情</summary>
                <div ddz-class="here-need-to-handle-by-highlight-and-request-html" data-url="./source/api.txt" ddz-lang="python"></div>
            </details>
            <p>之后，你只需要<line-code>python api.py</line-code>即可，记得激活虚拟环境啊</p>
            <p>
                <img src="./image/17.png" alt="CosyVoice 项目，API 方式启动项目" />
            </p>
            <p>下面再看一下，利用接口文档测试接口的截图：</p>
            <p>
                <img src="./image/18.png" alt="CosyVoice 项目，API 方式启动项目，利用接口文档测试" />
            </p>
        </div>
    </body>
</html>
